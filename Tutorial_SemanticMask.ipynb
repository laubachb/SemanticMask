{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ff7816",
   "metadata": {},
   "source": [
    "# SemanticMask: A Contrastive View Design for Anomaly Detection in Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf8bba",
   "metadata": {},
   "source": [
    "This notebook describes the user-guide of SemanticMask and its variants using saheart dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30668852",
   "metadata": {},
   "source": [
    "### Necessary packages and functions call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a427275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from data_loader import load_saheart\n",
    "from train import ContrastiveEncoder,train_dnn\n",
    "#from train_position import ContrastiveEncoder_position,train_encoder_position\n",
    "from semanticmask_augmentation import MyDataset,MyDataset_position,MyDataset_description,MyDataset_test\n",
    "import random,os\n",
    "from evaluate import evaluate\n",
    "from evaluate_position import evaluate_position\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf04c316",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8b87b",
   "metadata": {},
   "source": [
    "Load original saheart dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fe16b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data: (462, 9)\n",
      "The shape of normal data: (302, 9)\n",
      "The shape of anomalous data: (160, 9)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid,x_test,y_test = load_saheart()\n",
    "#np.save('data/X_train_saheart.npy', x_train)  \n",
    "#np.save('data/y_train_saheart.npy', y_train)    all zeros \n",
    "#np.save('data/X_valid_saheart.npy', x_valid)    \n",
    "#np.save('data/y_valid_saheart.npy', y_valid)    all zeros \n",
    "#np.save('data/X_test_saheart.npy', x_test)   \n",
    "#np.save('data/y_test_saheart.npy', y_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ed1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The different permutations and partitions of normal data in the load_saheart() function can lead to minor fluctuations in the results. \n",
    "#To ensure better reproducibility, we provide the preprocessed datasets used in our paper.\n",
    "X_train = np.load('data/X_train_saheart.npy')   \n",
    "y_train = np.load('data/y_train_saheart.npy')  \n",
    "X_valid = np.load('data/X_valid_saheart.npy')    \n",
    "y_valid = np.load('data/y_valid_saheart.npy')\n",
    "X_test = np.load('data/X_test_saheart.npy')   \n",
    "y_test = np.load('data/y_test_saheart.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e36de",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddfc9482",
   "metadata": {},
   "outputs": [],
   "source": [
    " #f_label: The feature grouping results obtained by applying sentence-BERT and k-means clustering based on column names can be found in group.ipynb.\n",
    "f_label = np.array([1, 0, 1, 0, 1, 0, 0, 0, 0])  \n",
    "data_train__SemanticMask = MyDataset(X_train,y_train,f_label)\n",
    "data_train = MyDataset_test(X_train, y_train)\n",
    "data_valid = MyDataset_test(X_valid, y_valid)\n",
    "data_test = MyDataset_test(X_test, y_test)\n",
    "trainloader_SemanticMask = torch.utils.data.DataLoader(data_train__SemanticMask,batch_size=151)   \n",
    "trainloader = torch.utils.data.DataLoader(dataset=data_train,batch_size=151)\n",
    "validloader = torch.utils.data.DataLoader(dataset=data_valid,batch_size=75)\n",
    "testloader = torch.utils.data.DataLoader(dataset=data_test,batch_size=236)\n",
    "\n",
    "\n",
    "data_train_position = MyDataset_position(X_train,y_train,f_label)\n",
    "trainloader_position = torch.utils.data.DataLoader(data_train_position,batch_size=151)  \n",
    "\n",
    "# In this dataset, the partition results of SemanticMask and SemanticMask+description is same. \n",
    "f_label = np.array([1, 0, 1, 0, 1, 0, 0, 0, 0])\n",
    "data_train_description = MyDataset_description(X_train,y_train,f_label)\n",
    "trainloader_description = torch.utils.data.DataLoader(data_train_description,batch_size=151) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31e84b",
   "metadata": {},
   "source": [
    "**Hyperparameter setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e25fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b33c89",
   "metadata": {},
   "source": [
    "### Train the SemanticMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86fc8bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 217.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 10]\n",
      " [90 70]]\n",
      "AUCROC: 0.7209703947368422\n",
      "0.7209703947368422\n"
     ]
    }
   ],
   "source": [
    "# No need to call .cuda() anywhere in the code\n",
    "net = ContrastiveEncoder()  # Instantiate the model (no need for .cuda() here)\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "# Ensure the model and inputs are on the CPU\n",
    "net, training_loss = train_dnn(net, temperature, epochs, optimizer, trainloader_SemanticMask)\n",
    "\n",
    "AUC = []\n",
    "\n",
    "# Evaluate the model using CPU\n",
    "auroc = evaluate(net, trainloader, validloader, testloader)\n",
    "print(auroc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4dd100",
   "metadata": {},
   "source": [
    "**Report prediction performances of our pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608b499",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      3\u001b[0m     net \u001b[38;5;241m=\u001b[39m ContrastiveEncoder()\n\u001b[0;32m----> 4\u001b[0m     net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/SemanticMask_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     auroc \u001b[38;5;241m=\u001b[39mevaluate(net,trainloader,validloader,testloader)\n\u001b[1;32m      6\u001b[0m     AUC\u001b[38;5;241m.\u001b[39mappend(auroc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1361\u001b[0m             opened_zipfile,\n\u001b[1;32m   1362\u001b[0m             map_location,\n\u001b[1;32m   1363\u001b[0m             pickle_module,\n\u001b[1;32m   1364\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[1;32m   1365\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1366\u001b[0m         )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(\n\u001b[1;32m   1813\u001b[0m         dtype, nbytes, key, _maybe_decode_ascii(location)\n\u001b[1;32m   1814\u001b[0m     )\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1784\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1779\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1784\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1785\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1786\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1787\u001b[0m )\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1790\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:601\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 601\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(storage, location)\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:539\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    537\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 539\u001b[0m     device \u001b[38;5;241m=\u001b[39m _validate_device(location, backend_name)\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:508\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    506\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    516\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "AUC = []\n",
    "for i in range(5):\n",
    "    net = ContrastiveEncoder()\n",
    "    net = torch.load(\"model/SemanticMask_\"+str(i)+\".pkl\", map_location=torch.device('cpu'))\n",
    "    auroc =evaluate(net,trainloader,validloader,testloader)\n",
    "    AUC.append(auroc)\n",
    "AUC= np.array(AUC)\n",
    "print(AUC)\n",
    "print(\"The average value of AUCROC:\", np.mean(AUC))\n",
    "print(\"The standard deviation of AUCROC:\",np.std(AUC))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a30a2c",
   "metadata": {},
   "source": [
    "### Train the SemanticMask + position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff1ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:16<00:00, 59.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68   8]\n",
      " [102  58]]\n",
      "AUCROC: 0.7056743421052631\n",
      "0.7056743421052631\n"
     ]
    }
   ],
   "source": [
    "from train_position import ContrastiveEncoder,train_encoder_position\n",
    "net = ContrastiveEncoder().cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "net,training_loss = train_encoder_position(net,temperature,epochs,optimizer,trainloader_position)\n",
    "auroc =evaluate_position(net,trainloader,validloader,testloader)\n",
    "print(auroc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd043ae8",
   "metadata": {},
   "source": [
    "**Report prediction performances of our pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca166d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  9]\n",
      " [90 70]]\n",
      "AUCROC: 0.7412006578947369\n",
      "[[67  9]\n",
      " [96 64]]\n",
      "AUCROC: 0.6863486842105263\n",
      "[[63 13]\n",
      " [86 74]]\n",
      "AUCROC: 0.7053453947368421\n",
      "[[ 63  13]\n",
      " [100  60]]\n",
      "AUCROC: 0.6828947368421053\n",
      "[[ 66  10]\n",
      " [102  58]]\n",
      "AUCROC: 0.7114309210526315\n",
      "[0.74120066 0.68634868 0.70534539 0.68289474 0.71143092]\n",
      "0.7054440789473684\n",
      "0.02091646186391073\n"
     ]
    }
   ],
   "source": [
    "from train_position import ContrastiveEncoder,train_encoder_position\n",
    "AUC = []\n",
    "for i in range(5):\n",
    "    net = torch.load(\"model/position_\"+str(i)+\".pkl\")\n",
    "    auroc =evaluate_position(net,trainloader,validloader,testloader)\n",
    "    AUC.append(auroc)\n",
    "AUC= np.array(AUC)\n",
    "print(AUC)\n",
    "print(np.mean(AUC))\n",
    "print(np.std(AUC))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ebc6c",
   "metadata": {},
   "source": [
    "### Train the SemanticMask + description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342c3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 117.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64 12]\n",
      " [81 79]]\n",
      "AUCROC: 0.7168585526315789\n",
      "0.7168585526315789\n"
     ]
    }
   ],
   "source": [
    "from train import ContrastiveEncoder,train_dnn\n",
    "\n",
    "net = ContrastiveEncoder().cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "Encoder,training_loss = train_dnn(net,temperature,epochs,optimizer,trainloader_description)\n",
    "auroc =evaluate(net,trainloader,validloader,testloader)\n",
    "print(auroc)  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5adc0",
   "metadata": {},
   "source": [
    "**Report prediction performances of our pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0494ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 13]\n",
      " [86 74]]\n",
      "AUCROC: 0.7111019736842106\n",
      "[[68  8]\n",
      " [92 68]]\n",
      "AUCROC: 0.7615131578947368\n",
      "[[67  9]\n",
      " [99 61]]\n",
      "AUCROC: 0.7041940789473684\n",
      "[[60 16]\n",
      " [86 74]]\n",
      "AUCROC: 0.7092927631578949\n",
      "[[63 13]\n",
      " [95 65]]\n",
      "AUCROC: 0.7038651315789474\n",
      "[0.71110197 0.76151316 0.70419408 0.70929276 0.70386513]\n",
      "0.7179934210526315\n",
      "0.021941701827476186\n"
     ]
    }
   ],
   "source": [
    "from train import ContrastiveEncoder,train_dnn\n",
    "AUC = []\n",
    "for i in range(5):\n",
    "    net = torch.load(\"model/description_\"+str(i)+\".pkl\")\n",
    "    auroc =evaluate(net,trainloader,validloader,testloader)\n",
    "    AUC.append(auroc)\n",
    "AUC= np.array(AUC)\n",
    "print(AUC)\n",
    "print(np.mean(AUC))\n",
    "print(np.std(AUC))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e9b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
